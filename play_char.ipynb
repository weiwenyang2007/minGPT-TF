{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kamalkraj/minGPT-TF/blob/master/play_char.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xLaIP3ThsV4D",
    "outputId": "d14c0eda-80b2-4a01-a326-f167b5eb06c0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastprogress==0.2.3 in /usr/local/lib/python3.8/dist-packages (0.2.3)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 177, in emit\n",
      "    self.console.print(renderable, overflow=\"ignore\", crop=False, style=style)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1673, in print\n",
      "    extend(render(renderable, render_options))\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1305, in render\n",
      "    for render_output in iter_render:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 134, in __rich_console__\n",
      "    for line in lines:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/segment.py\", line 249, in split_lines\n",
      "    for segment in segments:\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/console.py\", line 1283, in render\n",
      "    renderable = rich_cast(renderable)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_vendor/rich/protocol.py\", line 36, in rich_cast\n",
      "    renderable = cast_method()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 130, in __rich__\n",
      "    pip_cmd = get_best_invocation_for_this_pip()\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/entrypoints.py\", line 58, in get_best_invocation_for_this_pip\n",
      "    if found_executable and os.path.samefile(\n",
      "  File \"/usr/lib/python3.8/genericpath.py\", line 101, in samefile\n",
      "    s2 = os.stat(f2)\n",
      "FileNotFoundError: [Errno 2] No such file or directory: '/usr/bin/pip'\n",
      "Call stack:\n",
      "  File \"/usr/local/bin/pip\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/main.py\", line 70, in main\n",
      "    return command.main(cmd_args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 101, in main\n",
      "    return self._main(args)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/base_command.py\", line 223, in _main\n",
      "    self.handle_pip_version_check(options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/cli/req_command.py\", line 190, in handle_pip_version_check\n",
      "    pip_self_version_check(session, options)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/self_outdated_check.py\", line 236, in pip_self_version_check\n",
      "    logger.warning(\"[present-rich] %s\", upgrade_prompt)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1458, in warning\n",
      "    self._log(WARNING, msg, args, **kwargs)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1589, in _log\n",
      "    self.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1599, in handle\n",
      "    self.callHandlers(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 1661, in callHandlers\n",
      "    hdlr.handle(record)\n",
      "  File \"/usr/lib/python3.8/logging/__init__.py\", line 954, in handle\n",
      "    self.emit(record)\n",
      "  File \"/usr/local/lib/python3.8/dist-packages/pip/_internal/utils/logging.py\", line 179, in emit\n",
      "    self.handleError(record)\n",
      "Message: '[present-rich] %s'\n",
      "Arguments: (UpgradePrompt(old='22.2.2', new='23.1.2'),)\n"
     ]
    }
   ],
   "source": [
    "! pip install fastprogress==0.2.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ectbkGZCtZY7",
    "outputId": "ffa08711-1ef8-4392-d015-d9b1d648fb79"
   },
   "outputs": [],
   "source": [
    "#!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6nR1nK54so_r"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from mingpt.model import GPT, GPTConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "vS1zBtijsyi7"
   },
   "outputs": [],
   "source": [
    "class CharDataset:\n",
    "\n",
    "    def __init__(self, data, block_size):\n",
    "        chars = sorted(list(set(data)))\n",
    "        data_size, vocab_size = len(data), len(chars)\n",
    "        print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "        \n",
    "        self.stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "        self.itos = { i:ch for i,ch in enumerate(chars) }\n",
    "        self.block_size = block_size\n",
    "        self.vocab_size = vocab_size\n",
    "        self.data = data\n",
    "    \n",
    "    def __len__(self):\n",
    "        return math.ceil(len(self.data) / (self.block_size + 1))\n",
    "\n",
    "    def __iter__(self):\n",
    "        # we're actually going to \"cheat\" and pick a spot in the dataset at random\n",
    "        for _ in range(self.__len__()):\n",
    "            i = np.random.randint(0, len(self.data) - (self.block_size + 1))\n",
    "            chunk = self.data[i:i+self.block_size+1]\n",
    "            dix = [self.stoi[s] for s in chunk]\n",
    "            x = tf.convert_to_tensor(dix[:-1], dtype=tf.int32)\n",
    "            y = tf.convert_to_tensor(dix[1:], dtype=tf.int32)\n",
    "            yield x, y\n",
    "    \n",
    "    __call__ = __iter__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pY0MWXIbs0o1"
   },
   "outputs": [],
   "source": [
    "block_size = 128 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dmESKrLxtTgk",
    "outputId": "79d3c344-2c08-47e2-83d8-ec651da2fd09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115395 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "text = open('input.txt', 'r').read()\n",
    "train_dataset_gen = CharDataset(text, block_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "j28w_BkjtqXN"
   },
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(train_dataset_gen,(tf.int32,tf.int32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "cLKzeZ1PttjO"
   },
   "outputs": [],
   "source": [
    "from mingpt.model import GPT, GPTConfig\n",
    "mconf = GPTConfig(train_dataset_gen.vocab_size, train_dataset_gen.block_size,\n",
    "                  n_layer=8, n_head=8, n_embd=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "gjwA59Jpt5hH"
   },
   "outputs": [],
   "source": [
    "from mingpt.trainer import Trainer, TrainerConfig\n",
    "\n",
    "# initialize a trainer instance and kick off training\n",
    "tconf = TrainerConfig(max_epochs=10, batch_size=64, learning_rate=6e-4,\n",
    "                      lr_decay=True, warmup_tokens=512*20, final_tokens=200*len(train_dataset_gen)*block_size,\n",
    "                      num_workers=4)\n",
    "trainer = Trainer(GPT, mconf, train_dataset, len(train_dataset_gen), None, None, tconf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "id": "73gbBIN8usA4",
    "outputId": "bcf87229-20d4-4072-82b4-9696cba771e4"
   },
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1: train loss 350.23410. lr 5.999636e-04\n",
      "epoch 2: train loss 295.87991. lr 5.998533e-04\n",
      "epoch 3: train loss 260.77359. lr 5.996690e-04\n",
      "epoch 4: train loss 235.39684. lr 5.994107e-04\n",
      "epoch 5: train loss 217.30246. lr 5.990785e-04\n",
      "epoch 6: train loss 204.98639. lr 5.986725e-04\n",
      "epoch 7: train loss 195.28625. lr 5.981929e-04\n",
      "epoch 8: train loss 188.95831. lr 5.976396e-04\n",
      "epoch 9: train loss 183.35428. lr 5.970130e-04\n",
      "epoch 10: train loss 178.87193. lr 5.963130e-04\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y68wlKY2uyg2",
    "outputId": "a20f2339-574c-49c5-c7df-a4609924e7b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O God, O God! and thou all the place.\n",
      "\n",
      "CLIFFFORD:\n",
      "I would be be this stone, but I steel think,\n",
      "That would be secret his hath hold makes to be proclaimes\n",
      "And strain thy lips and the ward trouble stay\n",
      "And not them, I see are aboard.\n",
      "\n",
      "PERDITA:\n",
      "The san true too, and less that be the dukest and life, then\n",
      "that we meast there's be the want of him and heaven\n",
      "At all this subjects such out a hall about.\n",
      "Here shall be so true, and we was a word\n",
      "the prayer of head of my cousin, we make me there lies.\n",
      "\n",
      "PETRUCHIO:\n",
      "Then, what now he hope out of thy body's daughter him.\n",
      "\n",
      "FLUMIA:\n",
      "This is murderer, though never she him be poilous too:\n",
      "Then he's a man bed a pleased.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "I pray you, sir, I talke you to the city:\n",
      "To say, I will say him to the mirdlain arms.\n",
      "\n",
      "PETRUCHIO:\n",
      "Why, my lord, that's yet all the seat.\n",
      "\n",
      "CURTIS:\n",
      "You're sent? I have been thee between still.\n",
      "\n",
      "LUCIO:\n",
      "The words then when thyself, and yet so the work this land.\n",
      "The life, then, therefore has been have\n",
      "stone the stear of mine, which now made them leaves,\n",
      "Where ways steal a bearing of senators,\n",
      "We hath been as the second of my son hearts,\n",
      "How should be and the mastes of her late of the wind.\n",
      "How thinks all the passs'd of the chold for heaven.\n",
      "\n",
      "CLIFFFORD:\n",
      "His silver some and seven a milded, business\n",
      "He had been my heaven, he's the mother's love of a life,\n",
      "I'll take this son of heaven,\n",
      "I'd not the dead of the sun of the weddding\n",
      "A pleasure o' the strange and before the parts.\n",
      "\n",
      "DUCHESS OF YORK:\n",
      "All me, my lord, I'll be too, so much an the loves\n",
      "And make me to me true be a bettter.\n",
      "\n",
      "PERDITA:\n",
      "As the like is so last, and let's and love.\n",
      "\n",
      "KING HENRY VI:\n",
      "We will not state the weell; as he, then, his heart thoughts the\n",
      "shoulder be plucks of the did way, the wrong'd,\n",
      "That thy dead touch'd hope to be part me, and let\n",
      "The world and my statutest of thine.\n",
      "\n",
      "LUCIO:\n",
      "He conform'd thee, then would have seen something son make\n",
      "To true, that the capparion with the duke.\n",
      "\n",
      "LUCIO:\n",
      "A place. What triumph, how shall be to heaven! I wish\n",
      "shall not t\n"
     ]
    }
   ],
   "source": [
    "# alright, let's sample some character-level shakespear\n",
    "from mingpt.utils import sample\n",
    "\n",
    "context = \"O God, O God!\"\n",
    "x = tf.convert_to_tensor([train_dataset_gen.stoi[s] for s in context], dtype=tf.int32)[None,...]\n",
    "y = sample(trainer.model, x, 2000, temperature=0.9, sample=True, top_k=5)[0]\n",
    "completion = ''.join([train_dataset_gen.itos[int(i)] for i in y])\n",
    "print(completion)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "play_char.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
